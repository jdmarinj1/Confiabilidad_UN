[
  {
    "objectID": "Cap1.html",
    "href": "Cap1.html",
    "title": "Probabilidad y estadística",
    "section": "",
    "text": "Universidad Nacional de Colombia - Sede Manizales\nConfiabilidad de sistemas eléctricos\nProfesor: Juan David Marín Jiménez\nManizales, marzo de 2025",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#definición-de-probabilidad",
    "href": "Cap1.html#definición-de-probabilidad",
    "title": "Probabilidad y estadística",
    "section": "Definición de probabilidad",
    "text": "Definición de probabilidad\nLa probabilidad es un concepto matemático fundamental que tiene aplicaciones en una amplia gama de disciplinas, desde la ciencia y la ingeniería hasta la economía y la medicina. En un mundo donde muchas situaciones futuras son inciertas,** la probabilidad constituye una herramienta esencial para modelar y analizar el comportamiento aleatorio de eventos..**\nEn este curso, exploraremos los fundamentos de la probabilidad con el objetivo de comprender su significado, aplicaciones y métodos principales. Aprenderemos cómo la probabilidad nos permite cuantificar la incertidumbre en eventos futuros y cómo se aplica en la toma de decisiones, la predicción de eventos y la formulación de modelos matemáticos.\nA través de ejemplos prácticos y teoría, exploraremos los fundamentos de la probabilidad, incluyendo la definición de eventos y espacios muestrales, la notación y cálculo de probabilidades. Además, discutiremos aplicaciones reales de la probabilidad en sistemas eléctricos, lo que nos permitirá comprender cómo este poderoso enfoque matemático tiene un impacto significativo en la comprensión y análisis del mundo que nos rodea.\nEste curso está diseñado para estudiantes interesados en desarrollar una comprensión sólida de la probabilidad y su aplicabilidad en el mundo real. A través de un enfoque riguroso pero accesible, exploraremos la riqueza y la versatilidad de la probabilidad como herramienta fundamental en la modelización y comprensión de eventos inciertos en el campo de los sistemas eléctricos.",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#la-probabilidad-y-la-estadística",
    "href": "Cap1.html#la-probabilidad-y-la-estadística",
    "title": "Probabilidad y estadística",
    "section": "La probabilidad y la estadística",
    "text": "La probabilidad y la estadística\nLa Teoría de Probabilidades y la Estadística son dos disciplinas matemáticas distintas, aunque comparten una estrecha relación en el campo de la ciencia de datos. Desde esta perspectiva, la principal aplicación de la Teoría de Probabilidades es la Estadística. Mientras que la Teoría de Probabilidades se enfoca en establecer modelos probabilísticos del mundo, la Estadística se basa en los datos disponibles para reconstruir el mejor modelo probabilístico posible.\nEn resumen, en la Teoría de Probabilidades se parte de un conocimiento previo exacto sobre las probabilidades, mientras que en la Estadística el punto de partida son los datos disponibles.",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#ejemplo",
    "href": "Cap1.html#ejemplo",
    "title": "Probabilidad y estadística",
    "section": "Ejemplo",
    "text": "Ejemplo\nExisten diversas maneras de comprender cómo la probabilidad cuantifica nuestra incertidumbre. Para evitar abordar de entrada una cuestión filosófica potencialmente complicada, comencemos por algo que tal vez nos resulte más familiar: una función de Python que genere “números aleatorios”, como la función randint de la librería numpy.random.\nUtilizando esta función, podemos realizar el experimento de lanzar repetidamente un dado de seis caras y registrar los resultados.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as st\nfrom scipy.optimize import minimize\n\n\n# Hagamos un experimento! Tiremos un dado 1000 veces.\n\nn_experimentos = 100\nresultados = np.random.randint(1, 7, size=n_experimentos)\nvalores = np.arange(1, 7)\nconteos = np.bincount(resultados)[1:]\n\nplt.bar(valores, conteos)\nplt.title(\"Resultados de lanzar un dado\")\nplt.xlabel(\"Valor obtenido\")\nplt.ylabel(\"Frecuencia\")\nplt.show()\n# Veamos cuántas veces se obtuvo cada cosa con un histograma\n\n\n\n\n\n\n\n\nVemos que salen más o menos en iguales proporciones, pero no exactamente.\nObservemos algunas cosas: * Cada vez que repetimos las 1000 tiradas, obtenemos algo ligeramente distinto (¡probarlo!). ¿Quiere eso decir que las probabilidades de sacar un cierto número están fluctuando en el tiempo? ¿O siempre es la misma probabilidad, por más que veamos resultados distintos? * Si repetimos con muchas más tiradas, vamos a ver que el resultado se hace mucho más consistente:\n\n# Hagamos un experimento! Tiremos un dado 1.000.000 veces.\n\nn_experimentos = 1000000\nresultados = np.random.randint(1, 7, size=n_experimentos)\nvalores = np.arange(1, 7)\nconteos = np.bincount(resultados)[1:]\n\nplt.bar(valores, conteos)\nplt.title(\"Resultados de lanzar un dado\")\nplt.xlabel(\"Valor obtenido\")\nplt.ylabel(\"Frecuencia\")\nplt.show()\n# Veamos cuántas veces se obtuvo cada cosa con un histograma\n\n\n\n\n\n\n\n\nPero para poder leer mejor esto, nos conviene normalizar el histograma, es decir dividir las alturas de las barras por el número total de experimentos, para obtener la fracción de veces que se obtuvo un cierto resultado.\n\nfracciones = conteos / n_experimentos\nplt.bar(valores, fracciones)\n\n\n\nplt.title(\"Resultados normalizador de lanzar un dado 1.000.000 de veces\")\nplt.xlabel(\"Valor obtenido\")\nplt.ylabel(\"Probabilidad\")\nplt.show()\n\n\n\n\n\n\n\n\nVemos que las fracciones son todas aproximadamente iguales a \\(0,17\\), que es aproximadamente lo mismo que \\(1/6 = 0,166666...\\).\nLa fracción de ocurrencias está acercándose a un cierto valor que no fluctúa con cada repetición del experimento (o con cada realización, que es la palabra que se usa en la jerga probabilística). Vendría bien ponerle nombre a esos números a los que tienden las alturas del histograma normalizado, ¿verdad? Bueno, podemos ponerle… Sí. Probabilidad.\nLa teoría de probabilidades nos sirve para definir de forma abstracta qué es una probabilidad. Puede que al principio no sea claro que la noción abstracta es la misma que estamos viendo acá, pero quédense tranquilos: la teoría termina demostrando matemáticamente que esta noción de probabilidad como “eso a lo que tiende el histograma” coincide con la definición abstracta. La teoría demuestra, por ejemplo, que a medida que tomo más y más muestras, el histograma normalizado se va pareciendo cada vez más a la distribución de probabilidad de nuestra variable aleatoria. Esto se relaciona con un teorema importante que mencionaremos más adelante: la Ley de los Grandes Números.",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#axiomas-de-una-medida-de-probabilidad",
    "href": "Cap1.html#axiomas-de-una-medida-de-probabilidad",
    "title": "Probabilidad y estadística",
    "section": "Axiomas de una medida de probabilidad",
    "text": "Axiomas de una medida de probabilidad\nEs importante saber que las medidas de probabilidad tienen ciertos axiomas que definen de una forma muy, muy precisa qué es la probabilidad. A veces esos axiomas van a sernos útiles y otras veces van a quedar como un detalle de bajo nivel. En el caso de un espacio muestral discreto como el del dado, estos axiomas son los siguientes (el caso continuo es importante pero matemáticamente un poco más involucrado, y lo mencionaremos más adelante).\nDefinición. Una medida de probabilidad (discreta) es una función \\(p\\) que le asigna a cada evento posible \\(E\\) un número positivo \\(p(E) &gt; 0\\), de forma tal que 1. si \\(E\\) y \\(V\\) son eventos disjuntos (como en el ejemplo de recién), \\(p(E \\cup V) = p(E) + p(V)\\). 2. \\(p(\\Omega) = 1\\)\nEl primer ítem dice que si dos eventos son incompatibles (nunca pueden ocurrir a la vez), la probabilidad del evento combinado “pasó \\(E\\) o pasó \\(V\\)”) es la suma de las probabilidades individuales. En el caso en que \\(\\Omega\\) es infinito (pero discreto, en general es el caso \\(\\Omega = \\mathbb{N}\\), los números naturales), la propiedad se extiende a colecciones infinitas de subconjuntos: si \\((E_i)_{i = 1,\\dots}\\) son infinitos subconjuntos de \\(\\Omega\\), todos disjuntos uno a otro (o sea, son eventos incompatibles), \\(p(\\bigcup_{i=1}^{\\infty} E_i) = \\sum_{i=1}^{\\infty} p(E_i)\\).\nEl segundo ítem dice que las probabilidades suman a uno: siempre alguna de todas las posibilidades tiene que haber ocurrido, y ningún evento puede tener probabilidad mayor a \\(1\\).\nPuede demostrarse a partir del primer axioma que si \\(E\\) y \\(V\\) no son disjuntos, en general vale la regla\n\\[ p(E \\cup V) = p(E) + p(V) - p(E \\cap V)\\]\nque resulta bastante útil para hacer cuentas.\n\nVolviendo al ejemplo\nEn este caso, partimos de la base de que todos los números ocurren con igual frecuencia. Es importante notar que esta es una hipótesis fáctica sobre el estado material del dado (que es simétrico y no está cargado) y sobre el proceso físico de tirado del dado (por ejemplo, asumimos que quien tira el dado no tiene un control sobrehumano sobre sus músculos que le permite asegurarse de que cierta cara del dado quedará boca arriba).\nUna vez hecha esta hipótesis, nuestro modelo dice que el número \\(i\\) sale \\(f_i = 1/6\\) de las veces. Los números \\(f_i\\), que son las frecuencias relativas de cada resultado, determinan la medida de probabilidad \\(p\\), pero \\(p\\) le asigna una probabilidad no solo a los eventos \\(\\{1\\}, \\{2\\}, \\dots \\{6\\}\\), sino que le asigna una probabilidad a cada subconjunto de \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\). Lo que ocurre es que todas las demás probabilidades pueden calcularse utilizando el axioma de la suma de probabilidades.\nPor ejemplo: ¿Cuál es la probabilidad de sacar un número par o un número que sea múltiplo de 3?\n\n\\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\), \\(A = \\text{par}\\), \\(B = \\text{multiplo de 3}\\)\n$ P(A) = = 0.5$\n$ P(B) = = $\n$ P(A B) = $, ya que $ A B = {6}$\n$P(A B) = + - = = $",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#regla-de-la-suma-de-probabilidades",
    "href": "Cap1.html#regla-de-la-suma-de-probabilidades",
    "title": "Probabilidad y estadística",
    "section": "Regla de la suma de probabilidades",
    "text": "Regla de la suma de probabilidades\n\n\\[ p(E \\cup V) = p(E) + p(V) - p(E \\cap V)\\]\n\nDonde:\n$p(E V) $ es la probabilidad que ocurra el evento E o V, o que ocurran ambos\n$p(E V) $ es la probabilidad que ocurran los eventos E y V\n # 3. Probabilidad condicional\nHasta ahora pudimos formalizar situaciones del mundo real en las cuales distintos eventos de interés no dependen unos de otros. Por ejemplo, al tirar dos dados, conocer el valor que adopta uno de los dos no cambia nuestras predicciones sobre el valor del otro. Son fenómenos descorrelacionados, o más precisamente hablando, son variables aleatorias independientes.\nPero es muy fácil comenzar a hacernos preguntas que exceden las herramientas que desarrollamos hasta ahora. Por ejemplo, supongamos que tiro dos dados A y B (\\(X_A, X_B \\sim U(1,\\dots,6)\\)) y escondo el resultado, pero les digo que la suma (\\(Y = X_A + X_B\\)) de los dos números es \\(8\\).\n¿Cuál debería ser su predicción sobre la probabilidad de que para el dado A haya salido un \\(2\\)?\n¿Y si les digo que la suma dio \\(9\\)?\nAlgo es seguro: la predicción tiene que cambiar de alguna manera según la información suministrada, ya que si la suma es \\(9\\), es absolutamente imposible que el dado A sea un \\(2\\) (habría que sumarle \\(7\\)), mientras que si es \\(8\\) sí hay alguna posibilidad, pero quizá menor que si la suma fuera \\(7\\).\nPara responder estas preguntas debemos introducir la noción de probabilidad condicional, tanto para eventos como para variables aleatorias.\nDefinición. Sea \\(\\Omega\\) un espacio muestral, \\(p\\) una medida de probabilidad sobre \\(\\Omega\\), y sea \\(E \\subseteq \\Omega\\) un evento con probabilidad no nula (\\(p(E) \\neq 0\\)). La probabilidad condicional dado \\(E\\) es una nueva medida de probabilidad \\(p(-|E)\\) definida según\n\\[ p(V|E) = \\frac{p(E \\cap V)}{p(E)}. \\]\nNoten que hay que pedir que \\(p(E) \\neq 0\\) para que esta fórmula tenga sentido.\nVeamos por qué tiene sentido esta fórmula con el ejemplo de los dados. La idea es esta: dado que pasó \\(E\\) (la suma de los dados es \\(8\\)), quiero saber la probabilidad de \\(V\\) (el dado A es un \\(2\\)). Para eso, tengo que mirar todas las situaciones posibles (todos los \\(\\omega \\in \\Omega\\)) en las que haya pasado \\(E\\). En nuestro caso, esas situaciones son \\((2, 6), (3, 5), (4, 4), (5, 3)\\) y \\((6, 2)\\). Ahora, de esas situaciones, miro aquellas en las que además pasó \\(V\\). Esto corresponde a tomar la intersección \\(E \\cap V\\). En nuestro caso, hay una única situación y es \\(\\omega = (2, 6)\\). Ahora tenemos que preguntarnos por la probabilidad de \\(E \\cap V = \\{(2, 6)\\}\\), pero no sobre todas las situaciones posibles del mundo, sino solo sobre las situaciones en las que ocurrió \\(E\\). Esto es una regla de tres simple: si ahora la probabilidad de \\(E\\) la tomamos, temporariamente, como igual a \\(1\\), cuál es la probabilidad correspondiente para \\(E \\cap V\\)?\n\\[\\begin{align}\np(E)& \\quad \\underline{\\hspace{3cm}}&1 \\\\\np(E \\cap V)& \\quad \\underline{\\hspace{3cm}}&?\n\\end{align}\\]\nPues claro, la respuesta es \\(\\frac{p(E \\cap V)}{p(E)}\\) que es la fórmula de arriba.\nEn nuestro caso, como la probabilidad de cada \\(\\omega\\) es la misma, la probabilidad de cada evento \\(W\\) es igual al número de elementos de \\(W\\), que llamamos \\(\\# W\\), dividido por el tamaño del espacio muestral, \\(N\\). Entonces podemos calcular el resultado así:\n\\[p(V|E) = \\frac{p(E \\cap V)}{p(E)} = \\frac{\\#(E \\cap V) / N}{\\# E / N} = \\frac{\\#(E \\cap V)}{\\# E}\\]\nEs decir, simplemente contamos qué fracción de las veces que pasó \\(E\\), también ocurrió \\(V\\). O sea que la probabilidad condicional de que haya salido un \\(2\\) en el dado A dado que la suma de los dos dados es \\(8\\), es igual a \\(1/5\\).",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#independencia",
    "href": "Cap1.html#independencia",
    "title": "Probabilidad y estadística",
    "section": "Independencia",
    "text": "Independencia\nEn este ejemplo de los dados, \\(p(V) \\neq p(V | E)\\). Esto nos dice que los eventos no son independientes, pues saber que uno ocurrió cambia la probabilidad de que el otro haya ocurrido. Decimos que dos eventos \\(A\\) y \\(B\\) son independientes si \\(P(A|B) = P(A)\\). En ese caso ocurre también que \\(p(B|A) = p(B)\\) y que\n\\[p(A \\cap B) = p(A) p(B).\\]\nDecimos que la probabilidad se factoriza como el producto de las probabilidades. Si \\(A\\) y \\(B\\) no fueran independientes, en general tenemos la factorización\n\\[p(A \\cap B) = p(A|B) p(B)\\]\nque no es más que reordenar la definición. Esta fórmula es muy útil: a veces lo que queremos saber es \\(p(A \\cap B)\\), la probabilidad de que hayan ocurrido \\(A\\) y \\(B\\) al mismo tiempo, y lo que sabemos es la probabilidad de que ocurra \\(B\\), y la probabilidad de que ocurra \\(A\\) dado que ocurrió \\(B\\).\nEjemplo, calcular la probabilidad que en el lanzamiento de un dado, sea el suceso A= que salga un 5 , si además se sabe que el suceso B (que salga un nº impar)",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#regla-de-la-multiplicación-de-probabilidades",
    "href": "Cap1.html#regla-de-la-multiplicación-de-probabilidades",
    "title": "Probabilidad y estadística",
    "section": "Regla de la multiplicación de probabilidades",
    "text": "Regla de la multiplicación de probabilidades\nSi la probabilidad de ocurrencia de un evento E es afectado por la ocurrencia de un evento V, entonces E y V son eventos no independientes.\nLa probabilidad condicional del evento V, dado que el evento E ya ocurrió, es denotada por: \\(p (V/E)\\)\n\n\\[ p(V \\cap E) = p (V/E) p(E) \\]\n\\[ p (V/E)  =  \\frac{p(V\\cap E)}{p(E)}   \\]\nSi los eventos son independientes, es decir, que la ocurrencia de E no afecta la ocurrencia de V\n\\[ p(V \\cap E) = p (V) p(E) \\]\n\nDonde:\n$p(E V) $ es la probabilidad que ocurran los eventos E y V",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#complementación",
    "href": "Cap1.html#complementación",
    "title": "Probabilidad y estadística",
    "section": "Complementación",
    "text": "Complementación\n\n\\[ p(E') = 1 -  p(E) \\]",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#el-teorema-de-bayes",
    "href": "Cap1.html#el-teorema-de-bayes",
    "title": "Probabilidad y estadística",
    "section": "El Teorema de Bayes",
    "text": "El Teorema de Bayes\nEnunciar el teorema no es más que reordenar algunas ecuaciones que ya conocemos.\nPor definición, \\(p(A|B) = p(A \\cap B) / p(B)\\). Reordenando como antes, tenemos \\(p(A \\cap B) = p(A|B) p(B)\\). Pero de la misma forma, porque \\(A \\cap B = B \\cap A\\), podemos obtener\n\\[p(A \\cap B) = p(B|A) p(B)\\]\nIgualando los términos del lado derecho y reordenando, obtenemos la fórmula conocida como Teorema de Bayes:\n\\[p(B|A) = \\frac{p(A|B) p(B)}{p(A)}\\]\nFíjense que la fórmula nos permite invertir los roles de \\(A\\) y \\(B\\). \\(p(A|B)\\) y \\(p(B|A)\\) no son lo mismo numéricamente, y conceptualmente representan cosas totalmente diferentes.",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#varianza-y-desviación-estándar",
    "href": "Cap1.html#varianza-y-desviación-estándar",
    "title": "Probabilidad y estadística",
    "section": "Varianza y desviación estándar",
    "text": "Varianza y desviación estándar\nA continuación, veamos la principal medida de variabilidad o dispersión de una distribución.\nDefinición. La varianza de una variable aleatoria \\(X\\) se define así:\n\nCaso discreto:\n\n\\[ \\text{Var}(X) = \\sum_{x=0}^n (x - \\mu_X)^2 p_X(x) \\]\nPor ejemplo si \\(X \\sim \\text{Binom}(n, p)\\), \\(\\text{Var}(X) = n p (1-p)\\).\n\nCaso continuo:\n\n\\[ \\text{Var}(X) = \\int_{- \\infty}^{+ \\infty} (x - \\mu_X)^2 f_X(x) dx\\]\nPor ejemplo si \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\), \\(\\text{Var}(X) = \\sigma^2\\). Se ve de la definición que la varianza es una especie de “desviación cuadrática media” respecto de la esperanza.\nEn general, para cualquier variable aleatoria (aunque no sea gaussiana), definimos su desviación estándar como \\(\\sigma_X = \\sqrt{\\text{Var}(X)}\\). En el caso de una gaussiana con parámetro \\(\\sigma\\), recuperamos \\(\\sigma_X = \\sigma\\). Al tomar raíz cuadrada, \\(\\sigma_X\\) tiene las mismas “unidades” que \\(X\\). Por ejemplo si \\(X\\) es la estatura en centímetros de un individuo en una población de personas (de forma que la distribución de alturas es la distribución de probabilidad de \\(X\\)), \\(\\sigma_X\\) es una medida en centímetros de cuánto suele variar la estatura de un individuo típico respecto de la esperanza \\(\\mu_X\\). Si usáramos la varianza, esa medida de dispersión estaría en centímetros cuadrados, lo cual no es tan fácilmente interpretable.\n\nLa varianza mide qué tan lejos puede “irse” \\(X\\) respecto de su esperanza, y esto puede cuantificarse con precisión preguntándonos cuál es la probabilidad de que \\(X\\) caiga dentro del intervalo \\((\\mu_X - \\sigma_X, \\mu + \\sigma_X)\\), o lo que es lo mismo, la probabilidad de que \\(|X-\\mu_X | \\leq \\sigma_X\\). Un caso muy importante es el de la distribución normal. En este caso, vale que siempre, para cualquier valor de los parámetros \\(\\mu\\) y \\(\\sigma\\) de la distribución,\n\\[ \\text{Pr}(|X - \\mu| \\leq \\sigma) \\simeq 0.68\\]\nEs decir que, por ejemplo, si la distribución de estaturas de individuos en una población fuera gaussiana, aproximadamente el \\(68\\%\\) de la población tendría una altura mayor a \\(\\mu - \\sigma\\) y menor a \\(\\mu + \\sigma\\). Verifiquémoslo en Python:\n\nmu = 5\nsigma = 2.5\ndist = st.norm(loc=mu, scale=sigma)\n# probabilidad contenida entre mu-sigma y mu+sigma\nz = dist.cdf(mu + sigma) - dist.cdf(mu - sigma)\nprint(\"La probabilidad contenida entre mu-sigma y mu+sigma es {:.2g}.\".format(z))\n\nLa probabilidad contenida entre mu-sigma y mu+sigma es 0.68.\n\n\n # 4. Confiabilidad de sistemas eléctricos\n#Definiciones\n1. Confiabilidad\n\\[ R(t) = \\int_{t}^{\\infty}  f(t) dt \\]\nDonde: R(t) es la confiabilidad de un sistema desde el tiempo t hasta infinito y f(t) es la función de densidad de probabilidad PDF.\n2. Función de densidad de probabilidad: Cada distribución de probabilidad tiene una única función y se utiliza la notación f(t). El área bajo la curva muestra la probabilidad relativa que ocurra una falla antes del tirmpo t. La probabilidad, la cual se convierte en una función de distribución acumulativa (CDF), se puede calcular así:\n\\[ F(t) = \\int_{0}^{t}  f(t) dt \\]\nDonde, F(t) es la probabilidad que falla ocurra antes del tiempo t. f(t) es la PDF de una falla\n3. Función de distribución acumulativa - Cumulative distribution function (CDF): Graficar F(t) nos da la CDF, que muestra la probabilidad de que ocurra una falla en el tiempo t.\nFinalmente, la función de confiabilidad R(t) es la probabilidad de que un componente no falle en el tiempo t. Por lo tanto R(t) = 1 –F(t).\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n4. Función de Riesgo: La función de riesgo, o tasa de riesgo, es la tasa de falla instantánea para la población restante en el tiempo t. Se denota como se muestra a continuación:\n\\[ H(t) =  \\frac{f(t)}{R(t)} \\]\n5. Distribución exponencial: La PDF para la distribución exponencial se muestra a continuación:\n\\[ f(t) = \\lambda e^{-\\lambda t}\\]\nPor lo tanto, la CDF es:\n\\[ f(t) = 1- e^{-\\lambda  t}\\]\nY la función de confiabilidad sería:\n\\[ R(t) = e^{-\\lambda  t}\\]\nλ is the failure rate (inverse of MTBF)\nt is the length of time the system must function\ne is the base of natural logarithms",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción",
    "section": "",
    "text": "Welcome to the Julia workshop for Data Science!\nThe goal for the workshop is to highlight the main features that make Julia an attractive option for data science programmers\nThe workshop is intended for any data scientist with experience in R and/or python who is interested in learning the attractive features of Julia for Data Science. No knowledge of Julia is required.\nWorkshop materials in the github repository julia-workshop\n\n\n\nAt the end of the tutorial, participants will be able to:\n\nIdentify the main features that make Julia an attractive language for Data Science\nSet up a Julia environment to run their data analysis\nEfficiently handle datasets (even across different languages) through Tables.jl and Arrow.jl\nFit (generalized) linear mixed models with MixedModels.jl\nCommunicate across languages (Julia, R, python)\n\nIntended audience and level: The tutorial is intended for any data scientist with experience in R and/or python who is interested in learning the attractive features of Julia for Data Science. No knowledge of Julia is required.",
    "crumbs": [
      "Inicio",
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#learning-objectives-for-tutorial",
    "href": "index.html#learning-objectives-for-tutorial",
    "title": "Introducción",
    "section": "Learning Objectives for Tutorial",
    "text": "Learning Objectives for Tutorial\nAt the end of the tutorial, participants will be able to:\n\nIdentify the main features that make Julia an attractive language for Data Science\nSet up a Julia environment to run their data analysis\nEfficiently handle datasets (even across different languages) through Tables.jl and Arrow.jl\nFit (generalized) linear mixed models with MixedModels.jl\nCommunicate across languages (Julia, R, python)\n\nIntended audience and level: The tutorial is intended for any data scientist with experience in R and/or python who is interested in learning the attractive features of Julia for Data Science. No knowledge of Julia is required.",
    "crumbs": [
      "Inicio",
      "Introducción"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Juan David Marín Jiménez  |  Ingeniero Electricista  |  Magister en Ingeniería Eléctrica  |  PhD en Ingeniería\n\nExperiencia docente de la Universidad Nacional de Colombia Sede Manizales en las asignaturas de:\nCampos Electromagnéticos\nPlaneamiento y diseño de instalaciones eléctricas bajo la metodología BIM\nSistemas Eléctricos de Distribución\nSubestaciones y Protecciones\nExperiencia en proyectos de Machine Learning y BigData aplicados al sector eléctrico en Colombia.\nExperiencia en proyectos de eficiencia energética, estudios de calidad de la potencia, termografías.\nExperiencia en diseño y construcción de proyectos de redes de distribución y subestaciones eléctricas.\nCompetencia en aplicación del Reglamento Técnico de Instalaciones Eléctricas (RETIE); Reglamento Técnico de Iluminación y Alumbrado Público (RETILAP); Norma Técnica Colombia NTC 2050 de 1998; National Electrical Code NEC 2023, NFPA 70, 70E, 72, IEC 60364.\nEstudios de coordinación de protecciones y Estudios de Puesta en Servicio aprobados por diferentes operadores de red en Colombia.",
    "crumbs": [
      "Inicio",
      "About"
    ]
  },
  {
    "objectID": "Cap2.html#universidad-nacional-de-colombia---sede-manizales",
    "href": "Cap2.html#universidad-nacional-de-colombia---sede-manizales",
    "title": "Objetivos de este Notebook",
    "section": "Universidad Nacional de Colombia - Sede Manizales",
    "text": "Universidad Nacional de Colombia - Sede Manizales\n\nConfiabilidad de sistemas eléctricos\n\n\nProfesor: Juan David Marín Jiménez",
    "crumbs": [
      "Inicio",
      "Universidad Nacional de Colombia - Sede Manizales"
    ]
  },
  {
    "objectID": "Cap2.html",
    "href": "Cap2.html",
    "title": "Confiabilidad de sistemas industriales",
    "section": "",
    "text": "Tabla de Contenido\n\nIntroducción\nFundamentos de la evaluación de la confiabilidad en sistemas eléctricos\nProbabilidad condicional\nEl caso continuo y la distribución normal\nMedidas de tendencia central y de variabilidad\nDos grandes Teoremas\nMaterial adicional\n\n # 1. Introducción\n#Objetivo\nDescribir la forma de realizar predicciones cuantitativas de confiabilidad y disponibilidad en configuraciones de sistemas de distribución de energía en la industria, teniendo en cuenta factores como índices de confiabilidad, datos de confiabilidad, definición de interrupciones y ecuaciones de confiabilidad. Además, se presentan ejemplos detallados de diferentes configuraciones de sistemas industriales para ilustrar cómo la falla de componentes afecta a la confiabilidad global en puntos de uso dentro de instalaciones industriales.\n # 2. Fundamentos de la evaluación de la confiabilidad en sistemas eléctricos\n\n\nÍndices de confiabilidad en sistemas eléctricos\nLos índices básicos de confiabilidad del sistema (IEEE Std 493™-1997) que han demostrado ser más útiles y significativos en el diseño de sistemas de distribución de energía son los siguientes:\n\nFrecuencia de interrupciones en puntos de carga.\nDuración esperada de los eventos de interrupción en puntos de carga.\n\nEstos índices se pueden calcular fácilmente utilizando los métodos que se describirán y referenciarán en este capítulo. Los dos índices básicos (frecuencia de interrupciones y duración esperada de las interrupciones) se pueden utilizar para calcular los siguientes índices que también son útiles en la planificación y diseño de sistemas de energía industriales y comerciales:\n\nTiempo total esperado (promedio) de interrupción por año (u otro período de tiempo)\nDisponibilidad o indisponibilidad del sistema medida en el punto de suministro de carga en cuestión\nEnergía esperada, pero no suministrada, por año\n\nEstos índices son herramientas importantes para evaluar la confiabilidad y disponibilidad de los sistemas de distribución de energía y pueden ayudar en la toma de decisiones en el diseño y planificación de dichos sistemas en entornos industriales y comerciales.\nEs importante tener en cuenta que el efecto disruptivo de las interrupciones de energía a menudo está relacionado de manera no lineal con la duración de la interrupción. Por lo tanto, a menudo es deseable calcular no solo una frecuencia general de interrupciones, sino también frecuencias de interrupciones categorizadas por las duraciones apropiadas. Esto permite una comprensión más detallada de cómo las interrupciones de energía afectan a un sistema en particular, considerando diferentes duraciones de interrupción y su impacto en la confiabilidad y disponibilidad del sistema.\n#Que es una Interrupción?\nEsta definición especifica la magnitud de la caída de voltaje y la duración mínima de ese período de voltaje reducido que resultaría en una pérdida de producción u otra función crítica para la planta, proceso o edificio en cuestión. Frecuentemente, las definiciones de interrupción se dan solo en términos de una duración mínima y asumen que el voltaje es cero durante ese período. Establecer una definición clara y bien definida de interrupción es un paso crucial en la evaluación de la confiabilidad, ya que sirve de base para recopilar y analizar datos de interrupciones, calcular índices de confiabilidad y tomar decisiones informadas sobre el diseño, mantenimiento y estrategias de mejora del sistema.\nPara el curso, cómo establecemos una interrupción ? CREG ?\nInstantáneas (menor a 1 min)\nTransitorias (1-5) min\nTemporales (mayor a 5 min)\n#Definición de la interrupción del servicio\nLa primera etapa en un estudio de confiabilidad de un sistema eléctrico de suministro de energía es evaluar cuidadosamente la calidad y continuidad del suministro de energía requerido por las cargas que deben ser atendidas. Esta evaluación se resume y se expresa en una definición de interrupción del servicio que se utilizará en los pasos siguientes del proceso de evaluación de confiabilidad.\n#Datos requeridos para la evaluación de la confiabilidad en sistemas La información necesaria para las evaluaciones cuantitativas de la confiabilidad de un sistema depende en cierta medida de la naturaleza del sistema estudiado y del nivel de detalle de la investigación. En general, sin embargo, los datos sobre el rendimiento de los componentes individuales, junto con los tiempos requeridos para realizar reparaciones o reemplazos, así como los tiempos de operaciones de conmutación, se resumen de la siguiente manera:\n\nTasas de falla (tasas de salida forzada) asociadas con diferentes modos de falla de los componentes.\nTiempo esperado (promedio) para reparar o reemplazar un componente fallido.\nTasa de interrupción programada (mantenimiento) de un componente.\nDuración esperada (promedio) de un evento de interrupción programada.\n\nLos datos de tiempo necesarios para las operaciones de conmutación manual o automática incluyen lo siguiente:\n\nTiempos esperados para abrir y cerrar un interruptor de circuito.\nTiempos esperados para abrir y cerrar un interruptor de desconexión o transferencia.\nTiempo esperado para reemplazar un fusible.\nTiempos esperados para realizar operaciones de emergencia.\n\nLos tiempos de conmutación deben estimarse para el sistema que se está estudiando en función de la experiencia, juicio de ingeniería y prácticas operativas anticipadas.\nSi es posible, los datos de los componentes deben basarse en el rendimiento histórico de componentes en un entorno similar al del sistema propuesto que se está estudiando.\n#Métodos para la evaluación de la confiabilidad\nHoy en día existen numerosas metodologías de confiabilidad informática disponibles para analizar configuraciones complejas de sistemas de energía industrial y comercial. En particular, en el curso nos centraremos en el uso de ETAP.\nEl método de conjunto mínimo de cortes se utilizará en el análisis de varios sistemas de distribución de energía eléctrica. El método es sistemático y directo, y se puede realizar tanto manualmente como con el uso de computadoras. Una característica importante de este método es que permite identificar fácilmente los puntos débiles del sistema, tanto numérica como no numéricamente, lo que permite centrar la atención del diseño en aquellas secciones o componentes del sistema que contribuyen más a la falta de confiabilidad del servicio.\nUno de los principales beneficios de un análisis de confiabilidad y disponibilidad es que se realiza un análisis disciplinado de las opciones alternativas en el diseño del sistema de distribución de energía. Al utilizar datos de confiabilidad publicados recopilados por una sociedad técnica de plantas industriales, se realiza el mejor intento posible de utilizar la experiencia histórica para ayudar en el diseño del nuevo sistema.\n\n\nProcedimiento Evaluación de la confiabilidad y disponibilidad de un sistema de potencia industrial de baja tensión\nConsideraciones:\n\nSolo se consideran fallas permanentes forzadas del equipo eléctrico\nSe asume que el mantenimiento programado se realizará en momentos en los que no se requiere salida de energía a 480V\nLa frecuencia de las fallas programadas y la duración promedio se pueden estimar y, si es necesario, se pueden agregar a las fallas forzadas dadas.\nSe considera una falla en el suministro de energía al punto de utilización de 480 V\nInterrupción: Pérdida completa de la energía de entrada durante más de 5 segundos.\nInterrupción del servicio: Esta definición de falla/interrupción puede tener un efecto en la determinación de la velocidad necesaria del equipo de transferencia automática que se utiliza en sistemas primarios-selectivos o secundarios-selectivos. En algunos casos, al realizar estudios de confiabilidad, puede ser necesario definir más detalladamente qué se considera una pérdida completa de energía entrante, por ejemplo, una caída de voltaje por debajo del 70%.\n\n\\(λ\\) = Tasa de falla (fallas por año)\n\\(r\\) = El tiempo promedio de inactividad por falla (horas por falla) es igual al tiempo promedio necesario para reparar o reemplazar un equipo después de una falla. En algunos casos, esto incluye el tiempo necesario para cambiar a un circuito alternativo cuando está disponible.\n##Procedimiento para el análisis de la confiabilidad y disponibilidad\nDef: La tasa de falla \\(λ\\) es una medida de la falta de confiabilidad. El producto \\(λr\\) (tasa de falla por tiempo promedio de inactividad por falla) es igual a las horas de inactividad forzada por año y puede considerarse una medida de la indisponibilidad forzada, ya que un factor de escala de 8760 convierte una cantidad en la otra. El tiempo promedio de inactividad por falla \\(r\\) podría llamarse capacidad de restauración.\nEn los ejemplos (serie y paralelo), se asume que las interrupciones programadas son cero y las unidades para \\(λ\\) y \\(r\\) son, respectivamente, fallas por año y horas de inactividad por falla.\nSe lo siguiente:\n\nLa tasa de falla de los componentes es constante con la edad.\nEl tiempo de interrupción después de una falla tiene una distribución exponencial.\nCada evento de falla es independiente de cualquier otro evento de falla.\nLos tiempos de funcionamiento de los componentes son mucho mayores que los tiempos de falla: \\(λ_ir_i\\) / 8760 &lt; 0.01.\n\nNotación:\n\\(f\\) = Frecuencia de fallas\n\\(λ_i\\) = Tasa de falla del i-ésimo componente expresada en fallas por hora\n\\(r_i\\) = Promedio de horas de tiempo de inactividad por falla para el i-ésimo componente\n\\(s\\) = En serie\n\\(p\\) = En paralelo\n\n\n\nimage.png\n\n\n\nFigura 1 - Elementos en serie\n\nPara los componentes en serie, se tiene:\n\\[ f_s = λ_1 + λ_2 \\]\n\\[ f_{s}r_s = λ_1r_1 + λ_2r_2 \\]\n\\[ rs \\cong  = \\frac{λ_1r_1 + λ_2r_2}{λ_1 + λ_2 } \\]\n\n\n\nimage.png\n\n\n\nFigura 2 - Elementos en paralelo\n\n\\[ f_p = \\frac{λ_3  λ_4 (r_3 + r_4) }{8760} \\]\n\\[ f_{p}r_p = \\frac{λ_3r_3  λ_4  r_4 }{8760} \\]\n\\[ rp =  \\frac{ r_3 r_4 }{ r_3 + r_4} \\]\n\nson aproximados y solo deben ser utilizados cuando ambos \\((λ3r3 / 8760)\\) y \\((λ4r4 / 8760)\\) sean menores a 0.01.\n\ndisponibilidad inherente (Ai): La probabilidad instantánea de que un componente o sistema esté operativo o inoperativo. Ai solo considera el tiempo de inactividad debido a reparaciones de fallas. No se incluye el tiempo logístico, el mantenimiento preventivo, etc\n#Confiabilidad del suministro de energía eléctrica de las empresas de servicios públicos a plantas industriales.\nLa tasa de falla y el tiempo promedio de inactividad por falla de los suministros de energía eléctrica de las empresas de servicios públicos se proporcionan en la Tabla 3-1. Esto incluye datos de confiabilidad tanto para circuitos individuales como para circuitos dobles. Las dos fuentes de energía en un suministro de energía eléctrica de circuito doble no son completamente independientes, y el análisis de confiabilidad y disponibilidad debe tener esto en cuenta.\nUna falla de un componente en la planta causa una indisponibilidad forzada del componente; es decir, el componente no puede cumplir su función prevista hasta que sea reparado o reemplazado. Los términos “falla” e “indisponibilidad forzada” a menudo se usan indistintamente para referirse a estos eventos.\n\n\n\nimage.png\n\n\nLos datos de confiabilidad sobre los modos de falla de los interruptores de circuito se muestran en la Tabla 3-2. Estos datos se utilizan para los interruptores de circuito de 480 V. Se asumirá que el modo de falla “arco mientras está abierto” para interruptores de circuito y desconectadores tiene una tasa de falla de 0.0.\n\n\n\nimage.png\n\n\n#Ejemplo 1: Análisis de conafiabilidad y disponibilidad de un sistema radial simple\nSe muestra un sistema radial simple en la Figura 3-3. La energía se recibe a 13.8 kV desde la compañía eléctrica. Pasa por una corta sección de cable a través del medidor primario, protección y sistema de control, y luego a través de un interruptor de circuito de 13.8 kV dentro de la planta industrial. El circuito continúa a través de un cable con longitud de 128.44 m en conducto subterráneo, y un cable con longitud de 91.44 m se empalma con el cable de longitud 182.88 m. El extremo del cable longitud de de 128.44 m está conectado a un interruptor de desconexión cerrado. Un corto tramo de cable conecta el interruptor de desconexión cerrado a un transformador, que reduce el voltaje a 480 V. El circuito continúa a través de un interruptor de circuito principal de 480 V, luego a una barra de bus de conmutador de 480 V y luego a través de un segundo interruptor de circuito de 480 V, 91.44 m de cable en conducto aéreo, hasta el punto donde se utiliza la energía en la planta industrial.\n\n\n\nimage.png\n\n\n\n\n\nimage.png",
    "crumbs": [
      "Inicio",
      "Confiabilidad de sistemas industriales"
    ]
  }
]
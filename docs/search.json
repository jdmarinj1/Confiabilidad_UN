[
  {
    "objectID": "Cap1.html",
    "href": "Cap1.html",
    "title": "Probabilidad y estadística",
    "section": "",
    "text": "Universidad Nacional de Colombia - Sede Manizales\nConfiabilidad de sistemas eléctricos\nProfesor: Juan David Marín Jiménez\nManizales, marzo de 2025",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#definición-de-probabilidad",
    "href": "Cap1.html#definición-de-probabilidad",
    "title": "Probabilidad y estadística",
    "section": "Definición de probabilidad",
    "text": "Definición de probabilidad\nLa probabilidad es un concepto matemático fundamental que tiene aplicaciones en una amplia gama de disciplinas, desde la ciencia y la ingeniería hasta la economía y la medicina. En un mundo donde muchas situaciones futuras son inciertas,** la probabilidad constituye una herramienta esencial para modelar y analizar el comportamiento aleatorio de eventos..**\nEn este curso, exploraremos los fundamentos de la probabilidad con el objetivo de comprender su significado, aplicaciones y métodos principales. Aprenderemos cómo la probabilidad nos permite cuantificar la incertidumbre en eventos futuros y cómo se aplica en la toma de decisiones, la predicción de eventos y la formulación de modelos matemáticos.\nA través de ejemplos prácticos y teoría, exploraremos los fundamentos de la probabilidad, incluyendo la definición de eventos y espacios muestrales, la notación y cálculo de probabilidades. Además, discutiremos aplicaciones reales de la probabilidad en sistemas eléctricos, lo que nos permitirá comprender cómo este poderoso enfoque matemático tiene un impacto significativo en la comprensión y análisis del mundo que nos rodea.\nEste curso está diseñado para estudiantes interesados en desarrollar una comprensión sólida de la probabilidad y su aplicabilidad en el mundo real. A través de un enfoque riguroso pero accesible, exploraremos la riqueza y la versatilidad de la probabilidad como herramienta fundamental en la modelización y comprensión de eventos inciertos en el campo de los sistemas eléctricos.",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#la-probabilidad-y-la-estadística",
    "href": "Cap1.html#la-probabilidad-y-la-estadística",
    "title": "Probabilidad y estadística",
    "section": "La probabilidad y la estadística",
    "text": "La probabilidad y la estadística\nLa Teoría de Probabilidades y la Estadística son dos disciplinas matemáticas distintas, aunque comparten una estrecha relación en el campo de la ciencia de datos. Desde esta perspectiva, la principal aplicación de la Teoría de Probabilidades es la Estadística. Mientras que la Teoría de Probabilidades se enfoca en establecer modelos probabilísticos del mundo, la Estadística se basa en los datos disponibles para reconstruir el mejor modelo probabilístico posible.\nEn resumen, en la Teoría de Probabilidades se parte de un conocimiento previo exacto sobre las probabilidades, mientras que en la Estadística el punto de partida son los datos disponibles.",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#ejemplo",
    "href": "Cap1.html#ejemplo",
    "title": "Probabilidad y estadística",
    "section": "Ejemplo",
    "text": "Ejemplo\nExisten diversas maneras de comprender cómo la probabilidad cuantifica nuestra incertidumbre. Para evitar abordar de entrada una cuestión filosófica potencialmente complicada, comencemos por algo que tal vez nos resulte más familiar: una función de Python que genere “números aleatorios”, como la función randint de la librería numpy.random.\nUtilizando esta función, podemos realizar el experimento de lanzar repetidamente un dado de seis caras y registrar los resultados.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as st\nfrom scipy.optimize import minimize\n\n\n# Hagamos un experimento! Tiremos un dado 1000 veces.\n\nn_experimentos = 100\nresultados = np.random.randint(1, 7, size=n_experimentos)\nvalores = np.arange(1, 7)\nconteos = np.bincount(resultados)[1:]\n\nplt.bar(valores, conteos)\nplt.title(\"Resultados de lanzar un dado\")\nplt.xlabel(\"Valor obtenido\")\nplt.ylabel(\"Frecuencia\")\nplt.show()\n# Veamos cuántas veces se obtuvo cada cosa con un histograma\n\n\n\n\n\n\n\n\nVemos que salen más o menos en iguales proporciones, pero no exactamente.\nObservemos algunas cosas: * Cada vez que repetimos las 1000 tiradas, obtenemos algo ligeramente distinto (¡probarlo!). ¿Quiere eso decir que las probabilidades de sacar un cierto número están fluctuando en el tiempo? ¿O siempre es la misma probabilidad, por más que veamos resultados distintos? * Si repetimos con muchas más tiradas, vamos a ver que el resultado se hace mucho más consistente:\n\n# Hagamos un experimento! Tiremos un dado 1.000.000 veces.\n\nn_experimentos = 1000000\nresultados = np.random.randint(1, 7, size=n_experimentos)\nvalores = np.arange(1, 7)\nconteos = np.bincount(resultados)[1:]\n\nplt.bar(valores, conteos)\nplt.title(\"Resultados de lanzar un dado\")\nplt.xlabel(\"Valor obtenido\")\nplt.ylabel(\"Frecuencia\")\nplt.show()\n# Veamos cuántas veces se obtuvo cada cosa con un histograma\n\n\n\n\n\n\n\n\nPero para poder leer mejor esto, nos conviene normalizar el histograma, es decir dividir las alturas de las barras por el número total de experimentos, para obtener la fracción de veces que se obtuvo un cierto resultado.\n\nfracciones = conteos / n_experimentos\nplt.bar(valores, fracciones)\n\n\n\nplt.title(\"Resultados normalizador de lanzar un dado 1.000.000 de veces\")\nplt.xlabel(\"Valor obtenido\")\nplt.ylabel(\"Probabilidad\")\nplt.show()\n\n\n\n\n\n\n\n\nVemos que las fracciones son todas aproximadamente iguales a \\(0,17\\), que es aproximadamente lo mismo que \\(1/6 = 0,166666...\\).\nLa fracción de ocurrencias está acercándose a un cierto valor que no fluctúa con cada repetición del experimento (o con cada realización, que es la palabra que se usa en la jerga probabilística). Vendría bien ponerle nombre a esos números a los que tienden las alturas del histograma normalizado, ¿verdad? Bueno, podemos ponerle… Sí. Probabilidad.\nLa teoría de probabilidades nos sirve para definir de forma abstracta qué es una probabilidad. Puede que al principio no sea claro que la noción abstracta es la misma que estamos viendo acá, pero quédense tranquilos: la teoría termina demostrando matemáticamente que esta noción de probabilidad como “eso a lo que tiende el histograma” coincide con la definición abstracta. La teoría demuestra, por ejemplo, que a medida que tomo más y más muestras, el histograma normalizado se va pareciendo cada vez más a la distribución de probabilidad de nuestra variable aleatoria. Esto se relaciona con un teorema importante que mencionaremos más adelante: la Ley de los Grandes Números.",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#axiomas-de-una-medida-de-probabilidad",
    "href": "Cap1.html#axiomas-de-una-medida-de-probabilidad",
    "title": "Probabilidad y estadística",
    "section": "Axiomas de una medida de probabilidad",
    "text": "Axiomas de una medida de probabilidad\nEs importante saber que las medidas de probabilidad tienen ciertos axiomas que definen de una forma muy, muy precisa qué es la probabilidad. A veces esos axiomas van a sernos útiles y otras veces van a quedar como un detalle de bajo nivel. En el caso de un espacio muestral discreto como el del dado, estos axiomas son los siguientes (el caso continuo es importante pero matemáticamente un poco más involucrado, y lo mencionaremos más adelante).\nDefinición. Una medida de probabilidad (discreta) es una función \\(p\\) que le asigna a cada evento posible \\(E\\) un número positivo \\(p(E) &gt; 0\\), de forma tal que 1. si \\(E\\) y \\(V\\) son eventos disjuntos (como en el ejemplo de recién), \\(p(E \\cup V) = p(E) + p(V)\\). 2. \\(p(\\Omega) = 1\\)\nEl primer ítem dice que si dos eventos son incompatibles (nunca pueden ocurrir a la vez), la probabilidad del evento combinado “pasó \\(E\\) o pasó \\(V\\)”) es la suma de las probabilidades individuales. En el caso en que \\(\\Omega\\) es infinito (pero discreto, en general es el caso \\(\\Omega = \\mathbb{N}\\), los números naturales), la propiedad se extiende a colecciones infinitas de subconjuntos: si \\((E_i)_{i = 1,\\dots}\\) son infinitos subconjuntos de \\(\\Omega\\), todos disjuntos uno a otro (o sea, son eventos incompatibles), \\(p(\\bigcup_{i=1}^{\\infty} E_i) = \\sum_{i=1}^{\\infty} p(E_i)\\).\nEl segundo ítem dice que las probabilidades suman a uno: siempre alguna de todas las posibilidades tiene que haber ocurrido, y ningún evento puede tener probabilidad mayor a \\(1\\).\nPuede demostrarse a partir del primer axioma que si \\(E\\) y \\(V\\) no son disjuntos, en general vale la regla\n\\[ p(E \\cup V) = p(E) + p(V) - p(E \\cap V)\\]\nque resulta bastante útil para hacer cuentas.\n\nVolviendo al ejemplo\nEn este caso, partimos de la base de que todos los números ocurren con igual frecuencia. Es importante notar que esta es una hipótesis fáctica sobre el estado material del dado (que es simétrico y no está cargado) y sobre el proceso físico de tirado del dado (por ejemplo, asumimos que quien tira el dado no tiene un control sobrehumano sobre sus músculos que le permite asegurarse de que cierta cara del dado quedará boca arriba).\nUna vez hecha esta hipótesis, nuestro modelo dice que el número \\(i\\) sale \\(f_i = 1/6\\) de las veces. Los números \\(f_i\\), que son las frecuencias relativas de cada resultado, determinan la medida de probabilidad \\(p\\), pero \\(p\\) le asigna una probabilidad no solo a los eventos \\(\\{1\\}, \\{2\\}, \\dots \\{6\\}\\), sino que le asigna una probabilidad a cada subconjunto de \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\). Lo que ocurre es que todas las demás probabilidades pueden calcularse utilizando el axioma de la suma de probabilidades.\nPor ejemplo: ¿Cuál es la probabilidad de sacar un número par o un número que sea múltiplo de 3?\n\n\\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\), \\(A = \\text{par}\\), \\(B = \\text{multiplo de 3}\\)\n$ P(A) = = 0.5$\n$ P(B) = = $\n$ P(A B) = $, ya que $ A B = {6}$\n$P(A B) = + - = = $",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#regla-de-la-suma-de-probabilidades",
    "href": "Cap1.html#regla-de-la-suma-de-probabilidades",
    "title": "Probabilidad y estadística",
    "section": "Regla de la suma de probabilidades",
    "text": "Regla de la suma de probabilidades\n\n\\[ p(E \\cup V) = p(E) + p(V) - p(E \\cap V)\\]\n\nDonde:\n$p(E V) $ es la probabilidad que ocurra el evento E o V, o que ocurran ambos\n$p(E V) $ es la probabilidad que ocurran los eventos E y V\n # 3. Probabilidad condicional\nHasta ahora pudimos formalizar situaciones del mundo real en las cuales distintos eventos de interés no dependen unos de otros. Por ejemplo, al tirar dos dados, conocer el valor que adopta uno de los dos no cambia nuestras predicciones sobre el valor del otro. Son fenómenos descorrelacionados, o más precisamente hablando, son variables aleatorias independientes.\nPero es muy fácil comenzar a hacernos preguntas que exceden las herramientas que desarrollamos hasta ahora. Por ejemplo, supongamos que tiro dos dados A y B (\\(X_A, X_B \\sim U(1,\\dots,6)\\)) y escondo el resultado, pero les digo que la suma (\\(Y = X_A + X_B\\)) de los dos números es \\(8\\).\n¿Cuál debería ser su predicción sobre la probabilidad de que para el dado A haya salido un \\(2\\)?\n¿Y si les digo que la suma dio \\(9\\)?\nAlgo es seguro: la predicción tiene que cambiar de alguna manera según la información suministrada, ya que si la suma es \\(9\\), es absolutamente imposible que el dado A sea un \\(2\\) (habría que sumarle \\(7\\)), mientras que si es \\(8\\) sí hay alguna posibilidad, pero quizá menor que si la suma fuera \\(7\\).\nPara responder estas preguntas debemos introducir la noción de probabilidad condicional, tanto para eventos como para variables aleatorias.\nDefinición. Sea \\(\\Omega\\) un espacio muestral, \\(p\\) una medida de probabilidad sobre \\(\\Omega\\), y sea \\(E \\subseteq \\Omega\\) un evento con probabilidad no nula (\\(p(E) \\neq 0\\)). La probabilidad condicional dado \\(E\\) es una nueva medida de probabilidad \\(p(-|E)\\) definida según\n\\[ p(V|E) = \\frac{p(E \\cap V)}{p(E)}. \\]\nNoten que hay que pedir que \\(p(E) \\neq 0\\) para que esta fórmula tenga sentido.\nVeamos por qué tiene sentido esta fórmula con el ejemplo de los dados. La idea es esta: dado que pasó \\(E\\) (la suma de los dados es \\(8\\)), quiero saber la probabilidad de \\(V\\) (el dado A es un \\(2\\)). Para eso, tengo que mirar todas las situaciones posibles (todos los \\(\\omega \\in \\Omega\\)) en las que haya pasado \\(E\\). En nuestro caso, esas situaciones son \\((2, 6), (3, 5), (4, 4), (5, 3)\\) y \\((6, 2)\\). Ahora, de esas situaciones, miro aquellas en las que además pasó \\(V\\). Esto corresponde a tomar la intersección \\(E \\cap V\\). En nuestro caso, hay una única situación y es \\(\\omega = (2, 6)\\). Ahora tenemos que preguntarnos por la probabilidad de \\(E \\cap V = \\{(2, 6)\\}\\), pero no sobre todas las situaciones posibles del mundo, sino solo sobre las situaciones en las que ocurrió \\(E\\). Esto es una regla de tres simple: si ahora la probabilidad de \\(E\\) la tomamos, temporariamente, como igual a \\(1\\), cuál es la probabilidad correspondiente para \\(E \\cap V\\)?\n\\[\\begin{align}\np(E)& \\quad \\underline{\\hspace{3cm}}&1 \\\\\np(E \\cap V)& \\quad \\underline{\\hspace{3cm}}&?\n\\end{align}\\]\nPues claro, la respuesta es \\(\\frac{p(E \\cap V)}{p(E)}\\) que es la fórmula de arriba.\nEn nuestro caso, como la probabilidad de cada \\(\\omega\\) es la misma, la probabilidad de cada evento \\(W\\) es igual al número de elementos de \\(W\\), que llamamos \\(\\# W\\), dividido por el tamaño del espacio muestral, \\(N\\). Entonces podemos calcular el resultado así:\n\\[p(V|E) = \\frac{p(E \\cap V)}{p(E)} = \\frac{\\#(E \\cap V) / N}{\\# E / N} = \\frac{\\#(E \\cap V)}{\\# E}\\]\nEs decir, simplemente contamos qué fracción de las veces que pasó \\(E\\), también ocurrió \\(V\\). O sea que la probabilidad condicional de que haya salido un \\(2\\) en el dado A dado que la suma de los dos dados es \\(8\\), es igual a \\(1/5\\).",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#independencia",
    "href": "Cap1.html#independencia",
    "title": "Probabilidad y estadística",
    "section": "Independencia",
    "text": "Independencia\nEn este ejemplo de los dados, \\(p(V) \\neq p(V | E)\\). Esto nos dice que los eventos no son independientes, pues saber que uno ocurrió cambia la probabilidad de que el otro haya ocurrido. Decimos que dos eventos \\(A\\) y \\(B\\) son independientes si \\(P(A|B) = P(A)\\). En ese caso ocurre también que \\(p(B|A) = p(B)\\) y que\n\\[p(A \\cap B) = p(A) p(B).\\]\nDecimos que la probabilidad se factoriza como el producto de las probabilidades. Si \\(A\\) y \\(B\\) no fueran independientes, en general tenemos la factorización\n\\[p(A \\cap B) = p(A|B) p(B)\\]\nque no es más que reordenar la definición. Esta fórmula es muy útil: a veces lo que queremos saber es \\(p(A \\cap B)\\), la probabilidad de que hayan ocurrido \\(A\\) y \\(B\\) al mismo tiempo, y lo que sabemos es la probabilidad de que ocurra \\(B\\), y la probabilidad de que ocurra \\(A\\) dado que ocurrió \\(B\\).\nEjemplo, calcular la probabilidad que en el lanzamiento de un dado, sea el suceso A= que salga un 5 , si además se sabe que el suceso B (que salga un nº impar)",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#regla-de-la-multiplicación-de-probabilidades",
    "href": "Cap1.html#regla-de-la-multiplicación-de-probabilidades",
    "title": "Probabilidad y estadística",
    "section": "Regla de la multiplicación de probabilidades",
    "text": "Regla de la multiplicación de probabilidades\nSi la probabilidad de ocurrencia de un evento E es afectado por la ocurrencia de un evento V, entonces E y V son eventos no independientes.\nLa probabilidad condicional del evento V, dado que el evento E ya ocurrió, es denotada por: \\(p (V/E)\\)\n\n\\[ p(V \\cap E) = p (V/E) p(E) \\]\n\\[ p (V/E)  =  \\frac{p(V\\cap E)}{p(E)}   \\]\nSi los eventos son independientes, es decir, que la ocurrencia de E no afecta la ocurrencia de V\n\\[ p(V \\cap E) = p (V) p(E) \\]\n\nDonde:\n$p(E V) $ es la probabilidad que ocurran los eventos E y V",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#complementación",
    "href": "Cap1.html#complementación",
    "title": "Probabilidad y estadística",
    "section": "Complementación",
    "text": "Complementación\n\n\\[ p(E') = 1 -  p(E) \\]",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#el-teorema-de-bayes",
    "href": "Cap1.html#el-teorema-de-bayes",
    "title": "Probabilidad y estadística",
    "section": "El Teorema de Bayes",
    "text": "El Teorema de Bayes\nEnunciar el teorema no es más que reordenar algunas ecuaciones que ya conocemos.\nPor definición, \\(p(A|B) = p(A \\cap B) / p(B)\\). Reordenando como antes, tenemos \\(p(A \\cap B) = p(A|B) p(B)\\). Pero de la misma forma, porque \\(A \\cap B = B \\cap A\\), podemos obtener\n\\[p(A \\cap B) = p(B|A) p(B)\\]\nIgualando los términos del lado derecho y reordenando, obtenemos la fórmula conocida como Teorema de Bayes:\n\\[p(B|A) = \\frac{p(A|B) p(B)}{p(A)}\\]\nFíjense que la fórmula nos permite invertir los roles de \\(A\\) y \\(B\\). \\(p(A|B)\\) y \\(p(B|A)\\) no son lo mismo numéricamente, y conceptualmente representan cosas totalmente diferentes.",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "Cap1.html#varianza-y-desviación-estándar",
    "href": "Cap1.html#varianza-y-desviación-estándar",
    "title": "Probabilidad y estadística",
    "section": "Varianza y desviación estándar",
    "text": "Varianza y desviación estándar\nA continuación, veamos la principal medida de variabilidad o dispersión de una distribución.\nDefinición. La varianza de una variable aleatoria \\(X\\) se define así:\n\nCaso discreto:\n\n\\[ \\text{Var}(X) = \\sum_{x=0}^n (x - \\mu_X)^2 p_X(x) \\]\nPor ejemplo si \\(X \\sim \\text{Binom}(n, p)\\), \\(\\text{Var}(X) = n p (1-p)\\).\n\nCaso continuo:\n\n\\[ \\text{Var}(X) = \\int_{- \\infty}^{+ \\infty} (x - \\mu_X)^2 f_X(x) dx\\]\nPor ejemplo si \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\), \\(\\text{Var}(X) = \\sigma^2\\). Se ve de la definición que la varianza es una especie de “desviación cuadrática media” respecto de la esperanza.\nEn general, para cualquier variable aleatoria (aunque no sea gaussiana), definimos su desviación estándar como \\(\\sigma_X = \\sqrt{\\text{Var}(X)}\\). En el caso de una gaussiana con parámetro \\(\\sigma\\), recuperamos \\(\\sigma_X = \\sigma\\). Al tomar raíz cuadrada, \\(\\sigma_X\\) tiene las mismas “unidades” que \\(X\\). Por ejemplo si \\(X\\) es la estatura en centímetros de un individuo en una población de personas (de forma que la distribución de alturas es la distribución de probabilidad de \\(X\\)), \\(\\sigma_X\\) es una medida en centímetros de cuánto suele variar la estatura de un individuo típico respecto de la esperanza \\(\\mu_X\\). Si usáramos la varianza, esa medida de dispersión estaría en centímetros cuadrados, lo cual no es tan fácilmente interpretable.\n\nLa varianza mide qué tan lejos puede “irse” \\(X\\) respecto de su esperanza, y esto puede cuantificarse con precisión preguntándonos cuál es la probabilidad de que \\(X\\) caiga dentro del intervalo \\((\\mu_X - \\sigma_X, \\mu + \\sigma_X)\\), o lo que es lo mismo, la probabilidad de que \\(|X-\\mu_X | \\leq \\sigma_X\\). Un caso muy importante es el de la distribución normal. En este caso, vale que siempre, para cualquier valor de los parámetros \\(\\mu\\) y \\(\\sigma\\) de la distribución,\n\\[ \\text{Pr}(|X - \\mu| \\leq \\sigma) \\simeq 0.68\\]\nEs decir que, por ejemplo, si la distribución de estaturas de individuos en una población fuera gaussiana, aproximadamente el \\(68\\%\\) de la población tendría una altura mayor a \\(\\mu - \\sigma\\) y menor a \\(\\mu + \\sigma\\). Verifiquémoslo en Python:\n\nmu = 5\nsigma = 2.5\ndist = st.norm(loc=mu, scale=sigma)\n# probabilidad contenida entre mu-sigma y mu+sigma\nz = dist.cdf(mu + sigma) - dist.cdf(mu - sigma)\nprint(\"La probabilidad contenida entre mu-sigma y mu+sigma es {:.2g}.\".format(z))\n\nLa probabilidad contenida entre mu-sigma y mu+sigma es 0.68.\n\n\n # 4. Confiabilidad de sistemas eléctricos\n#Definiciones\n1. Confiabilidad\n\\[ R(t) = \\int_{t}^{\\infty}  f(t) dt \\]\nDonde: R(t) es la confiabilidad de un sistema desde el tiempo t hasta infinito y f(t) es la función de densidad de probabilidad PDF.\n2. Función de densidad de probabilidad: Cada distribución de probabilidad tiene una única función y se utiliza la notación f(t). El área bajo la curva muestra la probabilidad relativa que ocurra una falla antes del tirmpo t. La probabilidad, la cual se convierte en una función de distribución acumulativa (CDF), se puede calcular así:\n\\[ F(t) = \\int_{0}^{t}  f(t) dt \\]\nDonde, F(t) es la probabilidad que falla ocurra antes del tiempo t. f(t) es la PDF de una falla\n3. Función de distribución acumulativa - Cumulative distribution function (CDF): Graficar F(t) nos da la CDF, que muestra la probabilidad de que ocurra una falla en el tiempo t.\nFinalmente, la función de confiabilidad R(t) es la probabilidad de que un componente no falle en el tiempo t. Por lo tanto R(t) = 1 –F(t).\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\n4. Función de Riesgo: La función de riesgo, o tasa de riesgo, es la tasa de falla instantánea para la población restante en el tiempo t. Se denota como se muestra a continuación:\n\\[ H(t) =  \\frac{f(t)}{R(t)} \\]\n5. Distribución exponencial: La PDF para la distribución exponencial se muestra a continuación:\n\\[ f(t) = \\lambda e^{-\\lambda t}\\]\nPor lo tanto, la CDF es:\n\\[ f(t) = 1- e^{-\\lambda  t}\\]\nY la función de confiabilidad sería:\n\\[ R(t) = e^{-\\lambda  t}\\]\nλ is the failure rate (inverse of MTBF)\nt is the length of time the system must function\ne is the base of natural logarithms",
    "crumbs": [
      "Inicio",
      "Probabilidad y estadística"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción",
    "section": "",
    "text": "Welcome to the Julia workshop for Data Science!\nThe goal for the workshop is to highlight the main features that make Julia an attractive option for data science programmers\nThe workshop is intended for any data scientist with experience in R and/or python who is interested in learning the attractive features of Julia for Data Science. No knowledge of Julia is required.\nWorkshop materials in the github repository julia-workshop\n\n\n\nAt the end of the tutorial, participants will be able to:\n\nIdentify the main features that make Julia an attractive language for Data Science\nSet up a Julia environment to run their data analysis\nEfficiently handle datasets (even across different languages) through Tables.jl and Arrow.jl\nFit (generalized) linear mixed models with MixedModels.jl\nCommunicate across languages (Julia, R, python)\n\nIntended audience and level: The tutorial is intended for any data scientist with experience in R and/or python who is interested in learning the attractive features of Julia for Data Science. No knowledge of Julia is required.",
    "crumbs": [
      "Inicio",
      "Introducción"
    ]
  },
  {
    "objectID": "index.html#learning-objectives-for-tutorial",
    "href": "index.html#learning-objectives-for-tutorial",
    "title": "Introducción",
    "section": "",
    "text": "At the end of the tutorial, participants will be able to:\n\nIdentify the main features that make Julia an attractive language for Data Science\nSet up a Julia environment to run their data analysis\nEfficiently handle datasets (even across different languages) through Tables.jl and Arrow.jl\nFit (generalized) linear mixed models with MixedModels.jl\nCommunicate across languages (Julia, R, python)\n\nIntended audience and level: The tutorial is intended for any data scientist with experience in R and/or python who is interested in learning the attractive features of Julia for Data Science. No knowledge of Julia is required.",
    "crumbs": [
      "Inicio",
      "Introducción"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Juan David Marín Jiménez  |  Ingeniero Electricista  |  Magister en Ingeniería Eléctrica  |  PhD en Ingeniería\n\nExperiencia docente de la Universidad Nacional de Colombia Sede Manizales en las asignaturas de:\nCampos Electromagnéticos\nPlaneamiento y diseño de instalaciones eléctricas bajo la metodología BIM\nSistemas Eléctricos de Distribución\nSubestaciones y Protecciones\nExperiencia en proyectos de Machine Learning y BigData aplicados al sector eléctrico en Colombia.\nExperiencia en proyectos de eficiencia energética, estudios de calidad de la potencia, termografías.\nExperiencia en diseño y construcción de proyectos de redes de distribución y subestaciones eléctricas.\nCompetencia en aplicación del Reglamento Técnico de Instalaciones Eléctricas (RETIE); Reglamento Técnico de Iluminación y Alumbrado Público (RETILAP); Norma Técnica Colombia NTC 2050 de 1998; National Electrical Code NEC 2023, NFPA 70, 70E, 72, IEC 60364.\nEstudios de coordinación de protecciones y Estudios de Puesta en Servicio aprobados por diferentes operadores de red en Colombia.",
    "crumbs": [
      "Inicio",
      "About"
    ]
  }
]